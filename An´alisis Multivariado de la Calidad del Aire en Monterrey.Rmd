```{r}
rm(list=ls())
```

---
title: "Etapa 3"
author: "Samuel Reyes"
date: "2024-08-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
df=read.csv("daily_Average_Dataframe.csv")
head(df)

```

```{r}
# Seleccionar las variables para el análisis factorial (excluyendo FECHA y NO2_sureste)
df_af <- df[, !(names(df) %in% c("FECHA", "NO2_sureste"))]

# Eliminar las columnas específicas y las columnas no numéricas
df_af <- df_af[, sapply(df_af, is.numeric)]

head(df_af)

```

# Verificación de la Adecuación de los Datos para Análisis Factorial

```{r}
correlation_matrix_af <- cor(df_af, use = "complete.obs")
```

## Prueba de Esfericidad de Bartlett

```{r}
library(psych)
cortest.bartlett(correlation_matrix_af)
```

El p-valor es muy pequeño (0), lo que significa que podemos rechazar la hipótesis nula de que la matriz de correlación es una matriz identidad. Esto sugiere que las variables están correlacionadas y que es adecuado proceder con el análisis factorial.

## Medida de Adecuación Muestral KMO

```{r}
KMO(correlation_matrix_af)
```

Un valor de KMO de 0.91 es excelente. Esto indica que las variables tienen correlaciones parciales suficientes para justificar un análisis factorial.

# Realizar el Análisis Factorial

## Número de factores

```{r}
scree(correlation_matrix_af)
```

Se utilizarán 4 factores para el análisis factorial.

```{r}
par(mfrow = c(1, 1), cex = 0.5)  
modelo_varimax<-fa(df_af,nfactors = 5,rotate = "varimax",
              fa="minres")
fa.diagram(modelo_varimax)

```

```{r}
print(modelo_varimax$loadings,cut=0) 

```

```{r}
factor_scores=modelo_varimax$scores
write.csv(factor_scores,"scores_factorial.csv",row.names = FALSE)
```

# Regresion

```{r}
data_for_regression = data.frame(NO2_sureste = df$NO2_sureste, factor_scores)
write.csv(data_for_regression,"data_for_regression.csv",row.names = FALSE)

modelo_regresion =lm(NO2_sureste ~ ., data = data_for_regression)

summary(modelo_regresion)
AIC(modelo_regresion)
BIC(modelo_regresion)

```

# SARIMAX

```{r}
plot(df$NO2_sureste, type = "l", col = "black", lwd = 2, 
     main = "Serie Temporal del NO2 Sureste", 
     ylab = "NO2", xlab = "Tiempo")


plot(factor_scores[, 1], type = "l", col = "blue", lwd = 2, 
     main = "Serie Temporal del Factor 1", 
     ylab = "Factor 1", xlab = "Tiempo")

plot(factor_scores[, 2], type = "l", col = "red", lwd = 2, 
     main = "Serie Temporal del Factor 2", 
     ylab = "Factor 2", xlab = "Tiempo")

plot(factor_scores[, 3], type = "l", col = "green", lwd = 2, 
     main = "Serie Temporal del Factor 3", 
     ylab = "Factor 3", xlab = "Tiempo")

plot(factor_scores[, 4], type = "l", col = "purple", lwd = 2, 
     main = "Serie Temporal del Factor 4", 
     ylab = "Factor 4", xlab = "Tiempo")

```

```{r}
# Descomponer la serie temporal
ts_data <- ts(df$NO2_sureste, frequency = 7)  # Ajustar la frecuencia según la periodicidad esperada
decomposition <- decompose(ts_data)
plot(decomposition)

```

No hay tendencia y se muestra presencia de estacionalidad.

```{r}
library(tseries)
adf.test(ts_data)

```

Debido a que en la prueba Dickey-Fuller se obtuvo un valor p menor a 0.05, se tiene suficiente evidencia estadística para rechazar la hipótesis nula, que sugiere no estacionariedad. Es decir, la serie es estacionaria.

```{r}
library(forecast)
# Ajustar un modelo SARIMAX con los componentes principales como variables exógenas
sarimax_model <- auto.arima(ts_data, xreg = factor_scores, seasonal = TRUE)

# Resumen del modelo SARIMAX ajustado
summary(sarimax_model)

```

```{r}
checkresiduals(sarimax_model)

```
```{r}
library(car)
vif(modelo_regresion)

```

```{r}
library(nortest)
residuos <- residuals(sarimax_model)
qqnorm(residuos)
qqline(residuos, col="red")

```


```{r}
plot(fitted(modelo_regresion), residuos, main = "Residuos vs Valores Ajustados")
abline(h = 0, col = "red")
x|
```
