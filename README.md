# Portafolio
## Síntesis del Proyecto: Predicción de Inventario para Don Colchón
En este proyecto desarrollé un modelo predictivo para estimar la demanda de productos en una empresa del sector minorista utilizando técnicas avanzadas de estadística, minería de datos, aprendizaje automático supervisado y no supervisado, así como modelos de optimización de series temporales. La problemática central consistía en reducir el alto margen de error (60%) en las predicciones de inventario. Para abordar esto, apliqué la metodología CRISP-DM, enfocándome en la estructuración, limpieza y análisis exploratorio de grandes volúmenes de datos provenientes de múltiples sucursales.

Desde el punto de vista matemático y computacional, empleé modelos ARIMA y SARIMA para capturar patrones de temporalidad y estacionalidad en las ventas, y posteriormente construí modelos de redes neuronales LSTM para capturar relaciones no lineales y dependencias de largo plazo en las series. El modelo LSTM logró un desempeño sobresaliente, con un MAPE de 2.67%, muy por debajo del margen actual de error. El procesamiento y entrenamiento de modelos fue realizado con Python, utilizando bibliotecas como Pandas, NumPy, Matplotlib, Plotly, Scikit-learn y Keras, aprovechando su potencial para el análisis, visualización y modelado.

## Síntesis del Proyecto: Análisis Multivariado de Calidad del Aire en Monterrey
En este proyecto apliqué un enfoque integral basado en análisis estadístico avanzado, minería de datos y técnicas de aprendizaje automático supervisado, para estudiar los factores que influyen en los niveles de dióxido de nitrógeno (NO₂) en la zona metropolitana de Monterrey. El análisis se centró en una base de datos extensa y multivariada, con más de 240 variables y registros horarios, lo que requirió un proceso riguroso de limpieza, transformación e imputación de datos faltantes mediante interpolación temporal.

Inicialmente, utilicé análisis factorial para reducir la dimensionalidad del conjunto de datos y extraer factores latentes que representaran condiciones climáticas y patrones de contaminación. Estos factores fueron utilizados como variables independientes en un modelo de regresión lineal múltiple, obteniendo un coeficiente de determinación (R²) de 0.85, lo que indicó una fuerte capacidad explicativa. Posteriormente, integré estas variables en un modelo SARIMAX para capturar la estacionalidad y tendencia temporal en los niveles de NO₂, logrando un MAPE del 14.6%. Finalmente, implementé un modelo de XGBoost, capaz de capturar relaciones no lineales complejas, obteniendo un MAPE del 14.01%, confirmando su alta capacidad predictiva.

Todo el procesamiento fue realizado con herramientas como Python y R, utilizando bibliotecas como pandas, statsmodels, xgboost, y forecast. Este reto fue clave para fortalecer mis habilidades en el manejo de grandes volúmenes de datos, la preparación para entornos analíticos complejos y la validación de modelos interpretables y robustos para la toma de decisiones en problemas reales.

